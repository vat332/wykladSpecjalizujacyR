library(gmodels)
library(class)
library(caret)
# 1. Wczytać zestaw danych, który odpowiada ostatniej cyfrze z numeru albumu, do systemu R.
mydata <- read.csv("dane/letter-recognition.data", stringsAsFactors = FALSE, sep=",")
colnames(mydata) <- c("T","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12","X13","X14","X15","X16")
head(mydata)
str(mydata)
dim(mydata)
head(mydata)
summary(mydata)
#################
#####WYKRESY#####
#################
# 2.Wykonać badania eksploracyjne (EDA, ang. exploratory data analysis) zestawu danych.
ggplot(data=mydata,aes(X1)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="x-box poziome położenie prostokąta (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X2)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="y-box pionowe położenie prostokąta (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X3)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="szerokość prostokąta (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X4)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="wysokość pola (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X5)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="onpix wszystkie # na pikselach (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X6)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="x-bar średnia x na pikselach w pudełku (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X7)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="y-bar średnia y na pikselach w pudełku (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X8)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="x2bar średnia x wariancja (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X9)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="y2bar średnia y wariancja (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X10)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="xybar średnia korelacja xy (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X11)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="x2ybr średnia z x * x * y (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X12)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="xy2br średnia z x * y * y (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X13)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="x-ege średnia liczba krawędzi od lewej do prawej (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X14)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="xegvy korelacja x-ege z y (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X15)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="y-ege średnia liczba krawędzi od dołu do góry (liczba całkowita)",y="Liczba")
ggplot(data=mydata,aes(X16)) + geom_histogram(breaks=seq(0,15,by=1),color="black",fill="orange") + labs(x="yegvx korelacja y-ege z x (liczba całkowita)",y="Liczba")
ggplot(mydata,aes(x="",y=X1)) + geom_boxplot(fill = "#56B4E9", color = "red",width=0.5) + theme(axis.title.y=element_blank()) + labs(x="x-box poziome położenie prostokąta (liczba całkowita)")
ggplot(mydata,aes(x="",y=X2)) + geom_boxplot(fill = "#56B4E9", color = "red")+ theme(axis.title.y=element_blank()) + labs(x="y-box pionowe położenie prostokąta (liczba całkowita)")
ggplot(mydata,aes(x="",y=X3)) + geom_boxplot(fill = "#56B4E9", color = "red")+ theme(axis.title.y=element_blank()) + labs(x="szerokość prostokąta (liczba całkowita)")
ggplot(mydata,aes(x="",y=X4)) + geom_boxplot(fill = "#56B4E9", color = "red")+ theme(axis.title.y=element_blank()) + labs(x="wysokość pola (liczba całkowita)")
ggplot(mydata,aes(x="",y=X5)) + geom_boxplot(fill = "#913945", color = "green",width=0.5) + theme(axis.title.y=element_blank()) + labs(x="onpix wszystkie # na pikselach (liczba całkowita)")
ggplot(mydata,aes(x="",y=X6)) + geom_boxplot(fill = "#913945", color = "green")+ theme(axis.title.y=element_blank()) + labs(x="x-bar średnia x na pikselach w pudełku (liczba całkowita)")
ggplot(mydata,aes(x="",y=X7)) + geom_boxplot(fill = "#913945", color = "green")+ theme(axis.title.y=element_blank()) + labs(x="y-bar średnia y na pikselach w pudełku (liczba całkowita)")
ggplot(mydata,aes(x="",y=X8)) + geom_boxplot(fill = "#913945", color = "green")+ theme(axis.title.y=element_blank()) + labs(x="x2bar średnia x wariancja (liczba całkowita)")
ggplot(mydata,aes(x="",y=X9)) + geom_boxplot(fill = "#BE29EC", color = "orange",width=0.5) + theme(axis.title.y=element_blank()) + labs(x="y2bar średnia y wariancja (liczba całkowita)")
ggplot(mydata,aes(x="",y=X10)) + geom_boxplot(fill = "#BE29EC", color = "orange")+ theme(axis.title.y=element_blank()) + labs(x="xybar średnia korelacja xy (liczba całkowita)")
ggplot(mydata,aes(x="",y=X11)) + geom_boxplot(fill = "#BE29EC", color = "orange")+ theme(axis.title.y=element_blank()) + labs(x="x2ybr średnia z x * x * y (liczba całkowita)")
ggplot(mydata,aes(x="",y=X12)) + geom_boxplot(fill = "#BE29EC", color = "orange")+ theme(axis.title.y=element_blank()) + labs(x="xy2br średnia z x * y * y (liczba całkowita)")
ggplot(mydata,aes(x="",y=X13)) + geom_boxplot(fill = "#ABC8C2", color = "black",width=0.5) + theme(axis.title.y=element_blank()) + labs(x="x-ege średnia liczba krawędzi od lewej do prawej (liczba całkowita)")
ggplot(mydata,aes(x="",y=X14)) + geom_boxplot(fill = "#ABC8C2", color = "black")+ theme(axis.title.y=element_blank()) + labs(x="xegvy korelacja x-ege z y (liczba całkowita)")
ggplot(mydata,aes(x="",y=X15)) + geom_boxplot(fill = "#ABC8C2", color = "black")+ theme(axis.title.y=element_blank()) + labs(x="y-ege średnia liczba krawędzi od dołu do góry (liczba całkowita)")
ggplot(mydata,aes(x="",y=X16)) + geom_boxplot(fill = "#ABC8C2", color = "black")+ theme(axis.title.y=element_blank()) + labs(x="yegvx korelacja y-ege z x (liczba całkowita)")
# 3. Cecha decyzyjna to T czyli 1) a reszta to objaśniająca X1-X16
# 4. Stworzyć klasyfikator używający algorytmu KNN.
table(mydata$T)
mydata$T <- factor(mydata$T, levels = c("A", "B","C","D","E","F","G","H","I","J","K","L","M","N","O","P","Q","R","S","T","U","V","W","X","Y","Z"),
labels = c("1-type", "2-type","3-type","4-type","5-type","6-type","7-type","8-type","9-type","10-type","11-type","12-type","13-type","14-type","15-type","16-type","17-type","18-type","19-type","20-type","21-type","22-type","23-type","24-type","25-type","26-type"))
round(prop.table(table(mydata$T)) * 100, digits = 1)
summary(mydata[c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11", "X12", "X13", "X14", "X15", "X16")])
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
normalize(c(1, 2, 3, 4, 5))
normalize(c(10, 20, 30, 40, 50))
mydatanew <- as.data.frame(lapply(mydata[2:16], normalize))
summary(mydatanew$X1)
# create training and test data
mydata_train <- mydatanew[1:1000, ]
mydata_test <- mydatanew[1001:19999, ]
# create labels for training and test data
mydata_train_labels <- mydata[1:1000, 1]
mydata_test_labels <- mydata[1001:19999, 1]
## Step 3: Training a model on the data ----
# load the "class" library
library(class)
mydata_test_pred <- knn(train = mydata_train, test = mydata_test,
cl = mydata_train_labels, k = 21)
## Step 4: Evaluating model performance ----
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = mydata_test_labels, y = mydata_test_pred,
prop.chisq = FALSE)
## Step 5: Improving model performance ----
# use the scale() function to z-score standardize a data frame
mydata_z <- as.data.frame(scale(mydata[-1]))
# confirm that the transformation was applied correctly
#summary(wbcd_z$area_mean)
# create training and test datasets
mydata_train <- mydata_z[1:1000, ]
mydata_test <- mydata_z[1001:19999, ]
# re-classify test cases
mydata_test_pred <- knn(train = mydata_train, test = mydata_test,
cl = mydata_train_labels, k = 21)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = mydata_test_labels, y = mydata_test_pred,
prop.chisq = FALSE)
#5. Przeprowadzić klasyfikację dla różnych wartości K. Dla każdej wartości podać miarę accuracy (dokładności) klasyfikatora.
mydata_train <- mydatanew[1:1000, ]
mydata_test <- mydatanew[1001:19999, ]
mydata_test_pred <- knn(train = mydata_train, test = mydata_test, cl = mydata_train_labels, k=1)
CrossTable(x = mydata_test_labels, y = mydata_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(mydata_test_pred,mydata_test_labels)
sum(diag(confusion))/nrow(mydata_test)
mydata_test_pred <- knn(train = mydata_train, test = mydata_test, cl = mydata_train_labels, k=3)
CrossTable(x = mydata_test_labels, y = mydata_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(mydata_test_pred,mydata_test_labels)
sum(diag(confusion))/nrow(mydata_test)
mydata_test_pred <- knn(train = mydata_train, test = mydata_test, cl = mydata_train_labels, k=13)
CrossTable(x = mydata_test_labels, y = mydata_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(mydata_test_pred,mydata_test_labels)
sum(diag(confusion))/nrow(mydata_test)
mydata_test_pred <- knn(train = mydata_train, test = mydata_test, cl = mydata_train_labels, k=16)
CrossTable(x = mydata_test_labels, y = mydata_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(mydata_test_pred,mydata_test_labels)
sum(diag(confusion))/nrow(mydata_test)
mydata_test_pred <- knn(train = mydata_train, test = mydata_test, cl = mydata_train_labels, k=19)
CrossTable(x = mydata_test_labels, y = mydata_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(mydata_test_pred,mydata_test_labels)
sum(diag(confusion))/nrow(mydata_test)
mydata_test_pred <- knn(train = mydata_train, test = mydata_test, cl = mydata_train_labels, k=26)
CrossTable(x = mydata_test_labels, y = mydata_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(mydata_test_pred,mydata_test_labels)
sum(diag(confusion))/nrow(mydata_test)
n = nrow(mydata)
train = sample(1:n, size = round(0.7*n),replace = FALSE)
t1 = mydata[train,]
t2 = mydata[-train,]
n1 = nrow(t1)
n2 = nrow(t2)
labels <- t1[,1]
error.rate <- numeric(10)
for(i in 1:26)
{
knn.pred <- knn(t1[,-1],t2[,-1],labels, k = i)
error.rate[i] <- 1-mean(knn.pred == t2[,1])
}
View(mydata)
View(mydata)
View(mydata)
plot(1:26, error.rate,"b", pch = 20, col = "red", xlab = "K", ylab = "Error Rate")
pred <- knn(t1[,-1],t2[,-1],labels, k = 1)
table(pred,t2$T)
pred <- knn(t1[,-1],t2[,-1],labels, k = 3)
table(pred,t2$T)
pred <- knn(t1[,-1],t2[,-1],labels, k = 13)
table(pred,t2$T)
pred <- knn(t1[,-1],t2[,-1],labels, k = 16)
table(pred,t2$T)
pred <- knn(t1[,-1],t2[,-1],labels, k = 19)
table(pred,t2$T)
pred <- knn(t1[,-1],t2[,-1],labels, k = 26)
table(pred,t2$T)
CrossTable(x=t2$T,y=pred, prop.chisq = FALSE)
#6. Oszacować miary oceny klasyfikacji: Accuracy, Recall (Sensitivity), Specificity, false positive rate FPR, false discovery rate FDR, precyzję pozytywną, precyzję negatywną, F1– i Fbeta-score, współczynnik korelacji Matthews’a.
library(caret)
set.seed(0)
y <- sample(c(T,F),100,replace=T)
m1 <- y
m1_err <- sample(1:100,sample(15:30,1))
m1[m1_err]=!m1[m1_err]
y <- factor(y)
m1 <- factor(m1)
cm1 <- confusionMatrix(m1,y,positive="TRUE")
#ROC curve#
m2 <- sample(c(T,F),100,replace=T)
m2 <- factor(m2)
cm2 <- confusionMatrix(m2,y,positive="TRUE")
tablica <- cm1$table
tablica1 <- cm2$table
FPR1 <- tablica[1,2]/sum(tablica[1,])
FPR2 <- tablica1[1,2]/sum(tablica1[1,])
TPR1 <- tablica[2,2]/sum(tablica[2,])
TPR2 <- tablica1[2,2]/sum(tablica1[2,])
plot(function(x)x,xlim=c(0,1),ylim=c(0,1),xlab="False Positive Rate",
ylab="True Positive Rate",col="black")
points(FPR1,TPR1,col="red")
points(FPR2,TPR2,col="yellow")
rm(list = ls())
library(pROC)
library(ggplot2)
sim_dat <- read.csv('dane/letter-recognition.data', header = T)
head(sim_dat)
sim_roc <- roc(response = sim_dat$T,
predictor = sim_dat$X2,
levels = c('A','W'))
auc(sim_roc)
ggroc(sim_roc, legacy.axes = TRUE) +
labs(x = 'False-positive rate', y = 'True-positive rate', title = 'Simulated ROC curve') +
annotate('text', x = .5, y = .5, label = paste0('AUC: ',round(auc(sim_roc), digits = 2)))
#Sprawozdanie na przedmiot wykład specjalizujący – „Klasyfikacja za pomocą k-Najbliższych sąsiadów”
#Informatyka ogólna
#Wykonał: Murawski Damian
#Index: 155083
#Uniwersytet Warmińsko-Mazurski
#Wydział Matematyki i Informatyki (WMiI)
#Olsztyn, 13.12.2022r.
#Zadania które trzeba było wykonać w ramach zajęć:
#1.	Wczytać zestaw danych, który odpowiada ostatniej cyfrze z numeru albumu, do systemu R.
#2. Wykonać badania eksploracyjne (EDA, ang. exploratory data analysis) zestawu danych.
#3. Wyznaczyć cechę decyzyjną i cechy objaśniające.
#4. Stworzyć klasyfikator używający algorytmu KNN.
#5. Przeprowadzić klasyfikację dla różnych wartości K. Dla każdej wartości podać miarę accuracy (dokładności) klasyfikatora.
#6. Oszacować miary oceny klasyfikacji: Accuracy, Recall (Sensitivity), Specificity, false positive rate FPR, false discovery rate FDR, precyzję pozytywną, precyzję negatywną, F1– i Fbeta-score, współczynnik korelacji Matthews’a.
#7. Napisać sprawozdanie i wysłać pod adres matematyka@gmx.com
#Informacje o atrybucie:
#1) Class wine
#2) Alcohol
#3) Malic acid
#4) Ash
#5) Alcalinity of ash
#6) Magnesium
#7) Total phenols
#8) Flavanoids
#9) Nonflavanoid phenols
#10) Proanthocyanins
#11)Color intensity
#12)Hue
#13)OD280/OD315 of diluted wines
#14)Proline
#Zadanie 1-5
# 1. Wczytać zestaw danych, który odpowiada ostatniej cyfrze z numeru albumu, do systemu R.
# Dodalem również nazwy atrybutów oraz wymieszałem wiersze aby mieć bardziej losowe dane
# 2.Wykonać badania eksploracyjne (EDA, ang. exploratory data analysis) zestawu danych.
wine <- read.csv("wine.data", stringsAsFactors = FALSE)
colnames(wine) <- c("Class","Alcohol","Malic_acid","Ash","Alcalinity_of_ash","Magnesium","Total_phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color_intensity","Hue","OD280/OD315_of_diluted_wines","Proline")
wine = wine[sample(1:nrow(wine)), ]
head(wine)
# 3. Cecha decyzyjna to Class czyli 1) a reszta to objaśniająca 2-14
# 4. Stworzyć klasyfikator używający algorytmu KNN.
table(wine$Class)
wine$Class <- factor(wine$Class, levels = c("1", "2","3"),
labels = c("1-type", "2-type","3-type"))
round(prop.table(table(wine$Class)) * 100, digits = 1)
summary(wine[c("Alcohol", "Color_intensity", "Flavanoids")])
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
normalize(c(1, 2, 3, 4, 5))
normalize(c(10, 20, 30, 40, 50))
winenew <- as.data.frame(lapply(wine[2:14], normalize))
summary(winenew$Alcohol)
# create training and test data
wine_train <- winenew[1:141, ]
wine_test <- winenew[142:177, ]
# create labels for training and test data
wine_train_labels <- wine[1:141, 1]
wine_test_labels <- wine[142:177, 1]
## Step 3: Training a model on the data ----
# load the "class" library
library(class)
wine_test_pred <- knn(train = wine_train, test = wine_test,
cl = wine_train_labels, k = 21)
## Step 4: Evaluating model performance ----
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = wine_test_labels, y = wine_test_pred,
prop.chisq = FALSE)
## Step 5: Improving model performance ----
# use the scale() function to z-score standardize a data frame
wine_z <- as.data.frame(scale(wine[-1]))
# confirm that the transformation was applied correctly
#summary(wbcd_z$area_mean)
# create training and test datasets
wine_train <- wine_z[1:141, ]
wine_test <- wine_z[142:177, ]
# re-classify test cases
wine_test_pred <- knn(train = wine_train, test = wine_test,
cl = wine_train_labels, k = 21)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = wine_test_labels, y = wine_test_pred,
prop.chisq = FALSE)
#5. Przeprowadzić klasyfikację dla różnych wartości K. Dla każdej wartości podać miarę accuracy (dokładności) klasyfikatora.
wine_train <- winenew[1:141, ]
wine_test <- winenew[142:177, ]
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=1)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=5)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=11)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=15)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=21)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=27)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
#Sprawozdanie na przedmiot wykład specjalizujący – „Klasyfikacja za pomocą k-Najbliższych sąsiadów”
#Informatyka ogólna
#Wykonał: Murawski Damian
#Index: 155083
#Uniwersytet Warmińsko-Mazurski
#Wydział Matematyki i Informatyki (WMiI)
#Olsztyn, 13.12.2022r.
#Zadania które trzeba było wykonać w ramach zajęć:
#1.	Wczytać zestaw danych, który odpowiada ostatniej cyfrze z numeru albumu, do systemu R.
#2. Wykonać badania eksploracyjne (EDA, ang. exploratory data analysis) zestawu danych.
#3. Wyznaczyć cechę decyzyjną i cechy objaśniające.
#4. Stworzyć klasyfikator używający algorytmu KNN.
#5. Przeprowadzić klasyfikację dla różnych wartości K. Dla każdej wartości podać miarę accuracy (dokładności) klasyfikatora.
#6. Oszacować miary oceny klasyfikacji: Accuracy, Recall (Sensitivity), Specificity, false positive rate FPR, false discovery rate FDR, precyzję pozytywną, precyzję negatywną, F1– i Fbeta-score, współczynnik korelacji Matthews’a.
#7. Napisać sprawozdanie i wysłać pod adres matematyka@gmx.com
#Informacje o atrybucie:
#1) Class wine
#2) Alcohol
#3) Malic acid
#4) Ash
#5) Alcalinity of ash
#6) Magnesium
#7) Total phenols
#8) Flavanoids
#9) Nonflavanoid phenols
#10) Proanthocyanins
#11)Color intensity
#12)Hue
#13)OD280/OD315 of diluted wines
#14)Proline
#Zadanie 1-5
# 1. Wczytać zestaw danych, który odpowiada ostatniej cyfrze z numeru albumu, do systemu R.
# Dodalem również nazwy atrybutów oraz wymieszałem wiersze aby mieć bardziej losowe dane
# 2.Wykonać badania eksploracyjne (EDA, ang. exploratory data analysis) zestawu danych.
wine <- read.csv("wine.data", stringsAsFactors = FALSE)
colnames(wine) <- c("Class","Alcohol","Malic_acid","Ash","Alcalinity_of_ash","Magnesium","Total_phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color_intensity","Hue","OD280/OD315_of_diluted_wines","Proline")
wine = wine[sample(1:nrow(wine)), ]
head(wine)
# 3. Cecha decyzyjna to Class czyli 1) a reszta to objaśniająca 2-14
# 4. Stworzyć klasyfikator używający algorytmu KNN.
table(wine$Class)
wine$Class <- factor(wine$Class, levels = c("1", "2","3"),
labels = c("1-type", "2-type","3-type"))
round(prop.table(table(wine$Class)) * 100, digits = 1)
summary(wine[c("Alcohol", "Color_intensity", "Flavanoids")])
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
normalize(c(1, 2, 3, 4, 5))
normalize(c(10, 20, 30, 40, 50))
winenew <- as.data.frame(lapply(wine[2:14], normalize))
summary(winenew$Alcohol)
# create training and test data
wine_train <- winenew[1:141, ]
wine_test <- winenew[142:177, ]
# create labels for training and test data
wine_train_labels <- wine[1:141, 1]
wine_test_labels <- wine[142:177, 1]
## Step 3: Training a model on the data ----
# load the "class" library
library(class)
wine_test_pred <- knn(train = wine_train, test = wine_test,
cl = wine_train_labels, k = 21)
## Step 4: Evaluating model performance ----
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = wine_test_labels, y = wine_test_pred,
prop.chisq = FALSE)
## Step 5: Improving model performance ----
# use the scale() function to z-score standardize a data frame
wine_z <- as.data.frame(scale(wine[-1]))
# confirm that the transformation was applied correctly
#summary(wbcd_z$area_mean)
# create training and test datasets
wine_train <- wine_z[1:141, ]
wine_test <- wine_z[142:177, ]
# re-classify test cases
wine_test_pred <- knn(train = wine_train, test = wine_test,
cl = wine_train_labels, k = 21)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = wine_test_labels, y = wine_test_pred,
prop.chisq = FALSE)
#5. Przeprowadzić klasyfikację dla różnych wartości K. Dla każdej wartości podać miarę accuracy (dokładności) klasyfikatora.
wine_train <- winenew[1:141, ]
wine_test <- winenew[142:177, ]
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=1)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=5)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=11)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=15)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=21)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
wine_test_pred <- knn(train = wine_train, test = wine_test, cl = wine_train_labels, k=27)
CrossTable(x = wine_test_labels, y = wine_test_pred, prop.chisq=FALSE)
#Miara accuracy (dokładności) klasyfikatora.
confusion=table(wine_test_pred,wine_test_labels)
sum(diag(confusion))/nrow(wine_test)
#6. Oszacować miary oceny klasyfikacji: Accuracy, Recall (Sensitivity), Specificity, false positive rate FPR, false discovery rate FDR, precyzję pozytywną, precyzję negatywną, F1– i Fbeta-score, współczynnik korelacji Matthews’a.
library(caret)
#Generating  fake estimates of a pretend classifier#
set.seed(0)
y <- sample(c(T,F),177,replace=T)
m1 <- y
m1_err <- sample(1:177,sample(15:30,1))
m1[m1_err]=!m1[m1_err]
y <- factor(y)
m1 <- factor(m1)
cm1 <- confusionMatrix(m1,y,positive="TRUE")
#ROC curve#
m2 <- sample(c(T,F),177,replace=T)
m2 <- factor(m2)
cm2 <- confusionMatrix(m2,y,positive="TRUE")
tab1 <- cm1$table
tab2 <- cm2$table
FPR1 <- tab1[1,2]/sum(tab1[1,])
FPR2 <- tab2[1,2]/sum(tab2[1,])
TPR1 <- tab1[2,2]/sum(tab1[2,])
TPR2 <- tab2[2,2]/sum(tab2[2,])
plot(function(x)x,xlim=c(0,1),ylim=c(0,1),xlab="False Positive Rate",
ylab="True Positive Rate",col="red")
points(FPR1,TPR1,col="green")
points(FPR2,TPR2,col="blue")
############################
rm(list = ls())
library(pROC)
library(ggplot2)
# Read in simulated data
sim_dat <- read.csv("wine.data", stringsAsFactors = FALSE , header = T)
colnames(sim_dat) <- c("Class","Alcohol","Malic_acid","Ash","Alcalinity_of_ash","Magnesium","Total_phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color_intensity","Hue","OD280/OD315_of_diluted_wines","Proline")
sim_dat = sim_dat[sample(1:nrow(sim_dat)), ]
head(sim_dat)
# Use pROC calculate TPR/FPR across a range of classification thresholds
sim_roc <- roc(response = sim_dat$Class,
predictor = sim_dat$Malic_acid,
levels = c('1', '2'))
# Plot ROC curve
ggroc(sim_roc, legacy.axes = TRUE) +
labs(x = 'False-positive rate', y = 'True-positive rate', title = 'Simulated ROC curve')
# Calculate AUC using pROC::auc()
auc(sim_roc)
ggroc(sim_roc, legacy.axes = TRUE) +
labs(x = 'False-positive rate', y = 'True-positive rate', title = 'Simulated ROC curve') +
annotate('text', x = .5, y = .5, label = paste0('AUC: ',round(auc(sim_roc), digits = 2)))
#6. Oszacować miary oceny klasyfikacji: Accuracy, Recall (Sensitivity), Specificity, false positive rate FPR, false discovery rate FDR, precyzję pozytywną, precyzję negatywną, F1– i Fbeta-score, współczynnik korelacji Matthews’a.
library(caret)
#Generating  fake estimates of a pretend classifier#
set.seed(0)
y <- sample(c(T,F),177,replace=T)
m1 <- y
m1_err <- sample(1:177,sample(15:30,1))
m1[m1_err]=!m1[m1_err]
y <- factor(y)
m1 <- factor(m1)
cm1 <- confusionMatrix(m1,y,positive="TRUE")
#ROC curve#
m2 <- sample(c(T,F),177,replace=T)
m2 <- factor(m2)
cm2 <- confusionMatrix(m2,y,positive="TRUE")
tab1 <- cm1$table
tab2 <- cm2$table
FPR1 <- tab1[1,2]/sum(tab1[1,])
FPR2 <- tab2[1,2]/sum(tab2[1,])
TPR1 <- tab1[2,2]/sum(tab1[2,])
TPR2 <- tab2[2,2]/sum(tab2[2,])
plot(function(x)x,xlim=c(0,1),ylim=c(0,1),xlab="False Positive Rate",
ylab="True Positive Rate",col="red")
points(FPR1,TPR1,col="green")
points(FPR2,TPR2,col="blue")
############################
rm(list = ls())
library(pROC)
library(ggplot2)
# Read in simulated data
sim_dat <- read.csv("wine.data", stringsAsFactors = FALSE , header = T)
colnames(sim_dat) <- c("Class","Alcohol","Malic_acid","Ash","Alcalinity_of_ash","Magnesium","Total_phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color_intensity","Hue","OD280/OD315_of_diluted_wines","Proline")
sim_dat = sim_dat[sample(1:nrow(sim_dat)), ]
head(sim_dat)
# Use pROC calculate TPR/FPR across a range of classification thresholds
sim_roc <- roc(response = sim_dat$Class,
predictor = sim_dat$Malic_acid,
levels = c('1', '2'))
# Plot ROC curve
ggroc(sim_roc, legacy.axes = TRUE) +
labs(x = 'False-positive rate', y = 'True-positive rate', title = 'Simulated ROC curve')
# Calculate AUC using pROC::auc()
auc(sim_roc)
ggroc(sim_roc, legacy.axes = TRUE) +
labs(x = 'False-positive rate', y = 'True-positive rate', title = 'Simulated ROC curve') +
annotate('text', x = .5, y = .5, label = paste0('AUC: ',round(auc(sim_roc), digits = 2)))
